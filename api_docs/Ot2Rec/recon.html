<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>Ot2Rec.recon API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>Ot2Rec.recon</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Copyright 2021 Rosalind Franklin Institute
#
# Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
# either express or implied. See the License for the specific
# language governing permissions and limitations under the License.


import os
import argparse
import subprocess
import multiprocess as mp
import pandas as pd
from tqdm import tqdm
import yaml

from . import metadata as mdMod
from . import params as prmMod
from . import user_args as uaMod
from . import logger as logMod
from . import magicgui as mgMod


class Recon:
    &#34;&#34;&#34;
    Class encapsulating a Recon object
    &#34;&#34;&#34;

    def __init__(self,
                 project_name,
                 md_in,
                 params_in,
                 logger_in,
                 ):
        &#34;&#34;&#34;
        Initialising a Recon object

        Args:
            project_name (str): name of current project
            md_in (Metadata): metadata containing images to be put into stack(s) for alignment
            params_in (Params): parameters for stack creation
            logger_in (Logger): logger object to keep record of progress and errors
        &#34;&#34;&#34;

        self.proj_name = project_name

        self.logObj = logger_in

        self.mObj = md_in
        if self.mObj is not None:
            self.meta = pd.DataFrame(self.mObj.metadata)

        self.pObj = params_in
        self.params = self.pObj.params

        self._get_internal_metadata()
        self.no_processes = False

        self._process_list = self.params[&#39;System&#39;][&#39;process_list&#39;]
        self._check_reconned_images()

    def _get_internal_metadata(self):
        &#34;&#34;&#34;
        Method to prepare internal metadata for processing and checking
        &#34;&#34;&#34;
        self.basis_folder = self.params[&#39;System&#39;][&#39;output_path&#39;]
        if self.basis_folder.endswith(&#39;/&#39;):
            self.basis_folder = self.basis_folder[:-1]

        self.rootname = self.params[&#39;System&#39;][&#39;output_rootname&#39;]
        if self.rootname.endswith(&#39;_&#39;):
            self.rootname = self.rootname[:-1]

        self.suffix = self.params[&#39;System&#39;][&#39;output_suffix&#39;]
        if self.suffix.endswith(&#39;_&#39;):
            self.suffix = self.suffix[:-1]

        # Create the folders and dictionary for future reference
        self._path_dict = {}
        for curr_ts in self.params[&#39;System&#39;][&#39;process_list&#39;]:
            subfolder = f&#34;{self.basis_folder}/{self.rootname}_{int(curr_ts):04}{self.suffix}&#34;
            os.makedirs(subfolder, exist_ok=True)
            self._path_dict[curr_ts] = subfolder

        self._recon_images = pd.DataFrame(columns=[&#39;ts&#39;, &#39;align_output&#39;, &#39;recon_output&#39;])
        for curr_ts in self.params[&#39;System&#39;][&#39;process_list&#39;]:
            subfolder = f&#34;{self.basis_folder}/{self.rootname}_{int(curr_ts):04}{self.suffix}&#34;
            _to_append = pd.DataFrame({
                &#39;ts&#39;: [curr_ts],
                &#39;align_output&#39;: [f&#34;{subfolder}/{self.rootname}_{int(curr_ts):04}{self.suffix}_ali.mrc&#34;],
                &#39;recon_output&#39;: [f&#34;{subfolder}/{self.rootname}_{int(curr_ts):04}{self.suffix}_rec.mrc&#34;],
            })
            self._recon_images = pd.concat([self._recon_images, _to_append],
                                           ignore_index=True,
                                           )

    def _check_reconned_images(self):
        &#34;&#34;&#34;
        Method to check images which have already been reconstructed
        &#34;&#34;&#34;
        # Create new empty internal output metadata if no record exists
        if not os.path.isfile(self.proj_name + &#39;_recon_mdout.yaml&#39;):
            self.meta_out = pd.DataFrame(columns=self._recon_images.columns)

        # Read in serialised metadata and turn into DataFrame if record exists
        else:
            _meta_record = mdMod.read_md_yaml(project_name=self.proj_name,
                                              job_type=&#39;reconstruct&#39;,
                                              filename=self.proj_name + &#39;_recon_mdout.yaml&#39;)
            self.meta_out = pd.DataFrame(_meta_record.metadata)
        self.meta_out.drop_duplicates(inplace=True)

        # Compare output metadata and output folder
        # If a file (in specified TS) is in record but missing, remove from record
        if len(self.meta_out) &gt; 0:
            self._missing = self.meta_out.loc[~self.meta_out[&#39;recon_output&#39;].apply(lambda x: os.path.isfile(x))]
            self._missing_specified = pd.DataFrame(columns=self.meta.columns)

            for curr_ts in self.params[&#39;System&#39;][&#39;process_list&#39;]:
                _to_append = self._missing[self._missing[&#39;ts&#39;] == curr_ts]
                self._missing_specified = pd.concat([self._missing_specified, _to_append],
                                                    ignore_index=True,
                                                    )
            self._merged = self.meta_out.merge(self._missing_specified, how=&#39;left&#39;, indicator=True)
            self.meta_out = self.meta_out[self._merged[&#39;_merge&#39;] == &#39;left_only&#39;]

            if len(self._missing_specified) &gt; 0:
                self.logObj(f&#34;Info: {len(self._missing_specified)} images in record missing in folder. &#34;
                            &#34;Will be added back for processing.&#34;)

        # Drop the items in input metadata if they are in the output record
        _ignored = self._recon_images[self._recon_images.recon_output.isin(self.meta_out.recon_output)]
        if len(_ignored) &gt; 0 and len(_ignored) &lt; len(self._recon_images):
            self.logObj(f&#34;Info: {len(_ignored)} images had been processed and will be omitted.&#34;)
        elif len(_ignored) == len(self._recon_images):
            self.logObj(f&#34;Info: All specified images had been processed. Nothing will be done.&#34;)
            self.no_processes = True

        self._merged = self._recon_images.merge(_ignored, how=&#39;left&#39;, indicator=True)
        self._recon_images = self._recon_images[self._merged[&#39;_merge&#39;] == &#39;left_only&#39;]
        self._process_list = self._recon_images[&#39;ts&#39;].sort_values(ascending=True).unique().tolist()

    def _get_adoc(self):
        &#34;&#34;&#34;
        Method to create directives for batchtomo reconstruction
        &#34;&#34;&#34;

        # Template for directive file
        adoc_temp = f&#34;&#34;&#34;
setupset.currentStackExt = st
setupset.copyarg.stackext = st
setupset.copyarg.userawtlt = &lt;use_rawtlt&gt;
setupset.copyarg.pixel = &lt;pixel_size&gt;
setupset.copyarg.rotation = &lt;rot_angle&gt;
setupset.copyarg.gold = &lt;gold_size&gt;
setupset.systemTemplate = &lt;adoc_template&gt;

runtime.Fiducials.any.trackingMethod = 1

runtime.Positioning.any.sampleType = &lt;do_pos&gt;
runtime.Positioning.any.thickness = &lt;pos_thickness&gt;

runtime.AlignedStack.any.correctCTF = &lt;corr_ctf&gt;
runtime.AlignedStack.any.eraseGold = &lt;erase_gold&gt;
runtime.AlignedStack.any.filterStack = &lt;filter_stack&gt;
runtime.AlignedStack.any.binByFactor = &lt;stack_bin_factor&gt;

runtime.Reconstruction.any.useSirt = &lt;use_sirt&gt;
comparam.sirtsetup.sirtsetup.LeaveIterations = &lt;sirt_iter&gt;

comparam.tilt.tilt.THICKNESS = &lt;recon_thickness&gt;

runtime.Postprocess.any.doTrimvol = &lt;run_trimvol&gt;
runtime.Trimvol.any.reorient = &lt;trimvol_reorient&gt;
        &#34;&#34;&#34;

        convert_dict = {
            &#39;use_rawtlt&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;use_rawtlt&#39;] else 0,
            &#39;pixel_size&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;pixel_size&#39;],
            &#39;rot_angle&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;rot_angle&#39;],
            &#39;gold_size&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;gold_size&#39;],
            &#39;adoc_template&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;adoc_template&#39;],

            &#39;do_pos&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;positioning&#39;][&#39;do_positioning&#39;] else 0,
            &#39;pos_thickness&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;positioning&#39;][&#39;unbinned_thickness&#39;],

            &#39;corr_ctf&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;aligned_stack&#39;][&#39;correct_ctf&#39;] else 0,
            &#39;erase_gold&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;aligned_stack&#39;][&#39;erase_gold&#39;] else 0,
            &#39;filter_stack&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;aligned_stack&#39;][&#39;2d_filtering&#39;] else 0,
            &#39;stack_bin_factor&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;aligned_stack&#39;][&#39;bin_factor&#39;],

            &#39;recon_thickness&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;reconstruction&#39;][&#39;thickness&#39;],
            &#39;use_sirt&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;reconstruction&#39;][&#39;use_sirt&#39;] else 0,
            &#39;sirt_iter&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;reconstruction&#39;][&#39;sirt_iter&#39;],

            &#39;run_trimvol&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;postprocessing&#39;][&#39;run_trimvol&#39;] else 0,
            &#39;trimvol_reorient&#39;: {&#39;none&#39;: 0, &#39;flip&#39;: 1, &#39;rotate&#39;: 2}[
                self.params[&#39;BatchRunTomo&#39;][&#39;postprocessing&#39;][&#39;trimvol_reorient&#39;]]
        }

        for param in list(convert_dict.keys()):
            adoc_temp = adoc_temp.replace(f&#39;&lt;{param}&gt;&#39;, f&#39;{convert_dict[param]}&#39;)

        with open(&#39;./recon.adoc&#39;, &#39;w&#39;) as f:
            f.write(adoc_temp)

    def _get_brt_recon_command(self,
                               curr_ts: int,
                               ext=False,
                               ):
        &#34;&#34;&#34;
        Method to get command to run batchtomo for reconstruction

        Args:
            curr_ts: index of the tilt-series currently being processed

        Returns:
            list
        &#34;&#34;&#34;

        # Get indices of usable CPUs
        temp_cpu = [str(i) for i in range(1, mp.cpu_count() + 1)]

        cmd = [&#39;batchruntomo&#39;,
               &#39;-CPUMachineList&#39;, f&#34;{temp_cpu}&#34;,
               &#39;-GPUMachineList&#39;, &#39;1&#39;,
               &#39;-DirectiveFile&#39;, &#39;./recon.adoc&#39;,
               &#39;-RootName&#39;, f&#39;{self.rootname}_{curr_ts:04d}&#39;,
               &#39;-CurrentLocation&#39;, self._path_dict[curr_ts],
               &#39;-StartingStep&#39;, &#39;8&#39; if not ext else &#39;0&#39;,
               &#39;-EndingStep&#39;, &#39;20&#39; if not ext else &#39;0&#39;,
               ]

        return cmd

    def recon_stack(self, ext=False):
        &#34;&#34;&#34;
        Method to reconstruct specified stack(s) using IMOD batchtomo
        &#34;&#34;&#34;
        # Add log entry when job starts
        self.logObj(&#34;Ot2Rec-reconstruction (IMOD) started.&#34;)

        # Create adoc file
        self._get_adoc()

        error_count = 0
        tqdm_iter = tqdm(self._process_list, ncols=100)
        for curr_ts in tqdm_iter:
            tqdm_iter.set_description(f&#34;Reconstructing TS {curr_ts}...&#34;)

            # Get command for current tilt-series
            if ext:
                batchruntomo = subprocess.run(self._get_brt_recon_command(curr_ts, ext=True),
                                              stdout=subprocess.PIPE,
                                              stderr=subprocess.STDOUT,
                                              encoding=&#39;ascii&#39;,
                                              check=True
                )

            batchruntomo = subprocess.run(self._get_brt_recon_command(curr_ts, ext=False),
                                          stdout=subprocess.PIPE,
                                          stderr=subprocess.STDOUT,
                                          encoding=&#39;ascii&#39;,
                                          check=True
            )

            try:
                assert (not batchruntomo.stderr)
            except:
                error_count += 1
                self.logObj(level=&#34;warning&#34;,
                            message=f&#34;Batchtomo: An error has occurred ({batchruntomo.returncode}) on stack{curr_ts}.&#34;)
            else:
                self.stdout = batchruntomo.stdout
                self.update_recon_metadata()
                self.export_metadata()

        # Add log entry when job finishes
        if error_count == 0:
            self.logObj(&#34;All Ot2Rec-recon (IMOD) jobs successfully finished.&#34;)
        else:
            self.logObj(level=&#34;warning&#34;,
                        message=f&#34;All Ot2Rec-recon (IMOD) jobs finished. {error_count} of {len(tqdm_iter)} jobs failed.&#34;
            )


    def update_recon_metadata(self):
        &#34;&#34;&#34;
        Subroutine to update metadata after one set of runs
        &#34;&#34;&#34;

        # Search for files with output paths specified in the metadata
        # If the files don&#39;t exist, keep the line in the input metadata
        # If they do, move them to the output metadata

        _to_append = self._recon_images.loc[self._recon_images[&#39;recon_output&#39;].apply(lambda x: os.path.isfile(x))]
        self.meta_out = pd.concat([self.meta_out, _to_append],
                                  ignore_index=True)
        self._recon_images = self._recon_images.loc[~self._recon_images[&#39;recon_output&#39;].apply(
            lambda x: os.path.isfile(x))]

        # Sometimes data might be duplicated (unlikely) -- need to drop the duplicates
        self.meta_out.drop_duplicates(inplace=True)

    def export_metadata(self):
        &#34;&#34;&#34;
        Method to serialise output metadata, export as yaml
        &#34;&#34;&#34;

        yaml_file = self.proj_name + &#39;_recon_mdout.yaml&#39;
        meta_dict = self.meta_out.to_dict()
        meta_dict[&#39;recon_algor&#39;] = &#34;SIRT&#34; if self.params[&#34;BatchRunTomo&#34;][&#34;reconstruction&#34;][&#34;use_sirt&#34;] else &#34;WBP&#34;

        with open(yaml_file, &#39;w&#39;) as f:
            yaml.dump(self.meta_out.to_dict(), f, indent=4, sort_keys=False)


&#34;&#34;&#34;
PLUGIN METHODS
&#34;&#34;&#34;


def create_yaml(args=None):
    &#34;&#34;&#34;
    Subroutine to create new yaml file for IMOD reconstruction
    &#34;&#34;&#34;
    logger = logMod.Logger(log_path=&#34;o2r_imod_recon.log&#34;)

    # Parse user inputs
    if args is None:
        args = mgMod.get_args_recon.show(run=True)

    # Create the yaml file, then automatically update it
    prmMod.new_recon_yaml(args)
    update_yaml(args)

    logger(message=&#34;IMOD alignment metadata file created.&#34;)


def update_yaml(args):
    &#34;&#34;&#34;
    Subroutine to update yaml file for IMOD reconstruction

    Args:
        args (Namespace): Namespace generated with user inputs
    &#34;&#34;&#34;
    logger = logMod.Logger(log_path=&#34;o2r_imod_recon.log&#34;)

    # Check if recon and align yaml files exist
    recon_yaml_name = args.project_name.value + &#39;_recon.yaml&#39;
    align_yaml_name = args.project_name.value + &#39;_align.yaml&#39;
    if not os.path.isfile(recon_yaml_name):
        logger(level=&#34;error&#34;,
               message=&#34;IMOD reconstruction config file not found.&#34;)
        raise IOError(&#34;Error in Ot2Rec.main.update_recon_yaml: reconstruction config file not found.&#34;)
    if not os.path.isfile(align_yaml_name):
        logger(level=&#34;error&#34;,
               message=&#34;IMOD alignment config file not found.&#34;)
        raise IOError(&#34;Error in Ot2Rec.main.update_recon_yaml: alignment config file not found.&#34;)

    # Read in alignment metadata (as Pandas dataframe)
    align_md_name = args.project_name.value + &#39;_align_mdout.yaml&#39;
    with open(align_md_name, &#39;r&#39;) as f:
        align_md = pd.DataFrame(yaml.load(f, Loader=yaml.FullLoader))[[&#39;ts&#39;]]
    logger(message=&#34;IMOD alignment metadata read successfully.&#34;)

    # Read in previous alignment output metadata (as Pandas dataframe) for old projects
    recon_md_name = args.project_name.value + &#39;_recon_mdout.yaml&#39;
    if os.path.isfile(recon_md_name):
        is_old_project = True
        with open(recon_md_name, &#39;r&#39;) as f:
            recon_md = pd.DataFrame(yaml.load(f, Loader=yaml.FullLoader))[[&#39;ts&#39;]]
        logger(message=&#34;Previous IMOD reconstruction metadata found and read.&#34;)
    else:
        is_old_project = False
        logger(message=&#34;Previous IMOD reconstruction metadata not found.&#34;)

    # Diff the two dataframes to get numbers of tilt-series with unprocessed data
    if is_old_project:
        merged_md = align_md.merge(recon_md,
                                   how=&#39;outer&#39;,
                                   indicator=True)
        unprocessed_images = merged_md.loc[lambda x: x[&#39;_merge&#39;] == &#39;left_only&#39;]
    else:
        unprocessed_images = align_md
    unique_ts_numbers = unprocessed_images[&#39;ts&#39;].sort_values(ascending=True).unique().tolist()

    # Read in reconstruction yaml file, modify, and update
    # read in alignment yaml as well (some parameters depend on alignment settings)
    recon_params = prmMod.read_yaml(project_name=args.project_name.value,
                                    filename=recon_yaml_name)
    align_params = prmMod.read_yaml(project_name=args.project_name.value,
                                    filename=align_yaml_name)

    recon_params.params[&#39;System&#39;][&#39;output_rootname&#39;] = align_params.params[&#39;System&#39;][&#39;output_rootname&#39;]
    recon_params.params[&#39;System&#39;][&#39;output_suffix&#39;] = align_params.params[&#39;System&#39;][&#39;output_suffix&#39;]
    recon_params.params[&#39;System&#39;][&#39;process_list&#39;] = unique_ts_numbers

    recon_params.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;] = {key: value for key, value in align_params.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;].items() \
                                                    if key != &#39;stack_bin_factor&#39;}
    recon_params.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;pixel_size&#39;] = \
        align_params.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;pixel_size&#39;] * \
        align_params.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;stack_bin_factor&#39;]

    with open(recon_yaml_name, &#39;w&#39;) as f:
        yaml.dump(recon_params.params, f, indent=4, sort_keys=False)

    logger(message=&#34;IMOD reconstruction metadata updated.&#34;)


def run(exclusive=True, args_in=None):
    &#34;&#34;&#34;
    Method to run IMOD reconstruction
    &#34;&#34;&#34;
    logger = logMod.Logger(log_path=&#34;o2r_imod_recon.log&#34;)

    if exclusive:
        parser = argparse.ArgumentParser()
        parser.add_argument(&#34;project_name&#34;,
                            type=str,
                            help=&#34;Name of current project&#34;)

        args = parser.parse_args()
        project_name = args.project_name
    else:
        project_name = args_in.project_name.value

    # Check if prerequisite files exist
    recon_yaml = project_name + &#39;_recon.yaml&#39;
    align_md_file = project_name + &#39;_align_mdout.yaml&#39;

    # Read in config and metadata
    recon_config = prmMod.read_yaml(project_name=project_name,
                                    filename=recon_yaml)
    align_md = mdMod.read_md_yaml(project_name=project_name,
                                  job_type=&#39;reconstruct&#39;,
                                  filename=align_md_file)

    # Create Logger object
    log_path = &#34;./o2r_recon.log&#34;
    try:
        os.remove(log_path)
    except:
        pass
    logger = logMod.Logger(log_path=log_path)

    # Create Recon object
    recon_obj = Recon(project_name=project_name,
                      md_in=align_md,
                      params_in=recon_config,
                      logger_in=logger,
                      )

    # Run IMOD
    if not recon_obj.no_processes:
        recon_obj.recon_stack()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="Ot2Rec.recon.create_yaml"><code class="name flex">
<span>def <span class="ident">create_yaml</span></span>(<span>args=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Subroutine to create new yaml file for IMOD reconstruction</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_yaml(args=None):
    &#34;&#34;&#34;
    Subroutine to create new yaml file for IMOD reconstruction
    &#34;&#34;&#34;
    logger = logMod.Logger(log_path=&#34;o2r_imod_recon.log&#34;)

    # Parse user inputs
    if args is None:
        args = mgMod.get_args_recon.show(run=True)

    # Create the yaml file, then automatically update it
    prmMod.new_recon_yaml(args)
    update_yaml(args)

    logger(message=&#34;IMOD alignment metadata file created.&#34;)</code></pre>
</details>
</dd>
<dt id="Ot2Rec.recon.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>exclusive=True, args_in=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Method to run IMOD reconstruction</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(exclusive=True, args_in=None):
    &#34;&#34;&#34;
    Method to run IMOD reconstruction
    &#34;&#34;&#34;
    logger = logMod.Logger(log_path=&#34;o2r_imod_recon.log&#34;)

    if exclusive:
        parser = argparse.ArgumentParser()
        parser.add_argument(&#34;project_name&#34;,
                            type=str,
                            help=&#34;Name of current project&#34;)

        args = parser.parse_args()
        project_name = args.project_name
    else:
        project_name = args_in.project_name.value

    # Check if prerequisite files exist
    recon_yaml = project_name + &#39;_recon.yaml&#39;
    align_md_file = project_name + &#39;_align_mdout.yaml&#39;

    # Read in config and metadata
    recon_config = prmMod.read_yaml(project_name=project_name,
                                    filename=recon_yaml)
    align_md = mdMod.read_md_yaml(project_name=project_name,
                                  job_type=&#39;reconstruct&#39;,
                                  filename=align_md_file)

    # Create Logger object
    log_path = &#34;./o2r_recon.log&#34;
    try:
        os.remove(log_path)
    except:
        pass
    logger = logMod.Logger(log_path=log_path)

    # Create Recon object
    recon_obj = Recon(project_name=project_name,
                      md_in=align_md,
                      params_in=recon_config,
                      logger_in=logger,
                      )

    # Run IMOD
    if not recon_obj.no_processes:
        recon_obj.recon_stack()</code></pre>
</details>
</dd>
<dt id="Ot2Rec.recon.update_yaml"><code class="name flex">
<span>def <span class="ident">update_yaml</span></span>(<span>args)</span>
</code></dt>
<dd>
<div class="desc"><p>Subroutine to update yaml file for IMOD reconstruction</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>args</code></strong> :&ensp;<code>Namespace</code></dt>
<dd>Namespace generated with user inputs</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_yaml(args):
    &#34;&#34;&#34;
    Subroutine to update yaml file for IMOD reconstruction

    Args:
        args (Namespace): Namespace generated with user inputs
    &#34;&#34;&#34;
    logger = logMod.Logger(log_path=&#34;o2r_imod_recon.log&#34;)

    # Check if recon and align yaml files exist
    recon_yaml_name = args.project_name.value + &#39;_recon.yaml&#39;
    align_yaml_name = args.project_name.value + &#39;_align.yaml&#39;
    if not os.path.isfile(recon_yaml_name):
        logger(level=&#34;error&#34;,
               message=&#34;IMOD reconstruction config file not found.&#34;)
        raise IOError(&#34;Error in Ot2Rec.main.update_recon_yaml: reconstruction config file not found.&#34;)
    if not os.path.isfile(align_yaml_name):
        logger(level=&#34;error&#34;,
               message=&#34;IMOD alignment config file not found.&#34;)
        raise IOError(&#34;Error in Ot2Rec.main.update_recon_yaml: alignment config file not found.&#34;)

    # Read in alignment metadata (as Pandas dataframe)
    align_md_name = args.project_name.value + &#39;_align_mdout.yaml&#39;
    with open(align_md_name, &#39;r&#39;) as f:
        align_md = pd.DataFrame(yaml.load(f, Loader=yaml.FullLoader))[[&#39;ts&#39;]]
    logger(message=&#34;IMOD alignment metadata read successfully.&#34;)

    # Read in previous alignment output metadata (as Pandas dataframe) for old projects
    recon_md_name = args.project_name.value + &#39;_recon_mdout.yaml&#39;
    if os.path.isfile(recon_md_name):
        is_old_project = True
        with open(recon_md_name, &#39;r&#39;) as f:
            recon_md = pd.DataFrame(yaml.load(f, Loader=yaml.FullLoader))[[&#39;ts&#39;]]
        logger(message=&#34;Previous IMOD reconstruction metadata found and read.&#34;)
    else:
        is_old_project = False
        logger(message=&#34;Previous IMOD reconstruction metadata not found.&#34;)

    # Diff the two dataframes to get numbers of tilt-series with unprocessed data
    if is_old_project:
        merged_md = align_md.merge(recon_md,
                                   how=&#39;outer&#39;,
                                   indicator=True)
        unprocessed_images = merged_md.loc[lambda x: x[&#39;_merge&#39;] == &#39;left_only&#39;]
    else:
        unprocessed_images = align_md
    unique_ts_numbers = unprocessed_images[&#39;ts&#39;].sort_values(ascending=True).unique().tolist()

    # Read in reconstruction yaml file, modify, and update
    # read in alignment yaml as well (some parameters depend on alignment settings)
    recon_params = prmMod.read_yaml(project_name=args.project_name.value,
                                    filename=recon_yaml_name)
    align_params = prmMod.read_yaml(project_name=args.project_name.value,
                                    filename=align_yaml_name)

    recon_params.params[&#39;System&#39;][&#39;output_rootname&#39;] = align_params.params[&#39;System&#39;][&#39;output_rootname&#39;]
    recon_params.params[&#39;System&#39;][&#39;output_suffix&#39;] = align_params.params[&#39;System&#39;][&#39;output_suffix&#39;]
    recon_params.params[&#39;System&#39;][&#39;process_list&#39;] = unique_ts_numbers

    recon_params.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;] = {key: value for key, value in align_params.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;].items() \
                                                    if key != &#39;stack_bin_factor&#39;}
    recon_params.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;pixel_size&#39;] = \
        align_params.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;pixel_size&#39;] * \
        align_params.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;stack_bin_factor&#39;]

    with open(recon_yaml_name, &#39;w&#39;) as f:
        yaml.dump(recon_params.params, f, indent=4, sort_keys=False)

    logger(message=&#34;IMOD reconstruction metadata updated.&#34;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="Ot2Rec.recon.Recon"><code class="flex name class">
<span>class <span class="ident">Recon</span></span>
<span>(</span><span>project_name, md_in, params_in, logger_in)</span>
</code></dt>
<dd>
<div class="desc"><p>Class encapsulating a Recon object</p>
<p>Initialising a Recon object</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>project_name</code></strong> :&ensp;<code>str</code></dt>
<dd>name of current project</dd>
<dt><strong><code>md_in</code></strong> :&ensp;<code>Metadata</code></dt>
<dd>metadata containing images to be put into stack(s) for alignment</dd>
<dt><strong><code>params_in</code></strong> :&ensp;<code>Params</code></dt>
<dd>parameters for stack creation</dd>
<dt><strong><code>logger_in</code></strong> :&ensp;<code>Logger</code></dt>
<dd>logger object to keep record of progress and errors</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Recon:
    &#34;&#34;&#34;
    Class encapsulating a Recon object
    &#34;&#34;&#34;

    def __init__(self,
                 project_name,
                 md_in,
                 params_in,
                 logger_in,
                 ):
        &#34;&#34;&#34;
        Initialising a Recon object

        Args:
            project_name (str): name of current project
            md_in (Metadata): metadata containing images to be put into stack(s) for alignment
            params_in (Params): parameters for stack creation
            logger_in (Logger): logger object to keep record of progress and errors
        &#34;&#34;&#34;

        self.proj_name = project_name

        self.logObj = logger_in

        self.mObj = md_in
        if self.mObj is not None:
            self.meta = pd.DataFrame(self.mObj.metadata)

        self.pObj = params_in
        self.params = self.pObj.params

        self._get_internal_metadata()
        self.no_processes = False

        self._process_list = self.params[&#39;System&#39;][&#39;process_list&#39;]
        self._check_reconned_images()

    def _get_internal_metadata(self):
        &#34;&#34;&#34;
        Method to prepare internal metadata for processing and checking
        &#34;&#34;&#34;
        self.basis_folder = self.params[&#39;System&#39;][&#39;output_path&#39;]
        if self.basis_folder.endswith(&#39;/&#39;):
            self.basis_folder = self.basis_folder[:-1]

        self.rootname = self.params[&#39;System&#39;][&#39;output_rootname&#39;]
        if self.rootname.endswith(&#39;_&#39;):
            self.rootname = self.rootname[:-1]

        self.suffix = self.params[&#39;System&#39;][&#39;output_suffix&#39;]
        if self.suffix.endswith(&#39;_&#39;):
            self.suffix = self.suffix[:-1]

        # Create the folders and dictionary for future reference
        self._path_dict = {}
        for curr_ts in self.params[&#39;System&#39;][&#39;process_list&#39;]:
            subfolder = f&#34;{self.basis_folder}/{self.rootname}_{int(curr_ts):04}{self.suffix}&#34;
            os.makedirs(subfolder, exist_ok=True)
            self._path_dict[curr_ts] = subfolder

        self._recon_images = pd.DataFrame(columns=[&#39;ts&#39;, &#39;align_output&#39;, &#39;recon_output&#39;])
        for curr_ts in self.params[&#39;System&#39;][&#39;process_list&#39;]:
            subfolder = f&#34;{self.basis_folder}/{self.rootname}_{int(curr_ts):04}{self.suffix}&#34;
            _to_append = pd.DataFrame({
                &#39;ts&#39;: [curr_ts],
                &#39;align_output&#39;: [f&#34;{subfolder}/{self.rootname}_{int(curr_ts):04}{self.suffix}_ali.mrc&#34;],
                &#39;recon_output&#39;: [f&#34;{subfolder}/{self.rootname}_{int(curr_ts):04}{self.suffix}_rec.mrc&#34;],
            })
            self._recon_images = pd.concat([self._recon_images, _to_append],
                                           ignore_index=True,
                                           )

    def _check_reconned_images(self):
        &#34;&#34;&#34;
        Method to check images which have already been reconstructed
        &#34;&#34;&#34;
        # Create new empty internal output metadata if no record exists
        if not os.path.isfile(self.proj_name + &#39;_recon_mdout.yaml&#39;):
            self.meta_out = pd.DataFrame(columns=self._recon_images.columns)

        # Read in serialised metadata and turn into DataFrame if record exists
        else:
            _meta_record = mdMod.read_md_yaml(project_name=self.proj_name,
                                              job_type=&#39;reconstruct&#39;,
                                              filename=self.proj_name + &#39;_recon_mdout.yaml&#39;)
            self.meta_out = pd.DataFrame(_meta_record.metadata)
        self.meta_out.drop_duplicates(inplace=True)

        # Compare output metadata and output folder
        # If a file (in specified TS) is in record but missing, remove from record
        if len(self.meta_out) &gt; 0:
            self._missing = self.meta_out.loc[~self.meta_out[&#39;recon_output&#39;].apply(lambda x: os.path.isfile(x))]
            self._missing_specified = pd.DataFrame(columns=self.meta.columns)

            for curr_ts in self.params[&#39;System&#39;][&#39;process_list&#39;]:
                _to_append = self._missing[self._missing[&#39;ts&#39;] == curr_ts]
                self._missing_specified = pd.concat([self._missing_specified, _to_append],
                                                    ignore_index=True,
                                                    )
            self._merged = self.meta_out.merge(self._missing_specified, how=&#39;left&#39;, indicator=True)
            self.meta_out = self.meta_out[self._merged[&#39;_merge&#39;] == &#39;left_only&#39;]

            if len(self._missing_specified) &gt; 0:
                self.logObj(f&#34;Info: {len(self._missing_specified)} images in record missing in folder. &#34;
                            &#34;Will be added back for processing.&#34;)

        # Drop the items in input metadata if they are in the output record
        _ignored = self._recon_images[self._recon_images.recon_output.isin(self.meta_out.recon_output)]
        if len(_ignored) &gt; 0 and len(_ignored) &lt; len(self._recon_images):
            self.logObj(f&#34;Info: {len(_ignored)} images had been processed and will be omitted.&#34;)
        elif len(_ignored) == len(self._recon_images):
            self.logObj(f&#34;Info: All specified images had been processed. Nothing will be done.&#34;)
            self.no_processes = True

        self._merged = self._recon_images.merge(_ignored, how=&#39;left&#39;, indicator=True)
        self._recon_images = self._recon_images[self._merged[&#39;_merge&#39;] == &#39;left_only&#39;]
        self._process_list = self._recon_images[&#39;ts&#39;].sort_values(ascending=True).unique().tolist()

    def _get_adoc(self):
        &#34;&#34;&#34;
        Method to create directives for batchtomo reconstruction
        &#34;&#34;&#34;

        # Template for directive file
        adoc_temp = f&#34;&#34;&#34;
setupset.currentStackExt = st
setupset.copyarg.stackext = st
setupset.copyarg.userawtlt = &lt;use_rawtlt&gt;
setupset.copyarg.pixel = &lt;pixel_size&gt;
setupset.copyarg.rotation = &lt;rot_angle&gt;
setupset.copyarg.gold = &lt;gold_size&gt;
setupset.systemTemplate = &lt;adoc_template&gt;

runtime.Fiducials.any.trackingMethod = 1

runtime.Positioning.any.sampleType = &lt;do_pos&gt;
runtime.Positioning.any.thickness = &lt;pos_thickness&gt;

runtime.AlignedStack.any.correctCTF = &lt;corr_ctf&gt;
runtime.AlignedStack.any.eraseGold = &lt;erase_gold&gt;
runtime.AlignedStack.any.filterStack = &lt;filter_stack&gt;
runtime.AlignedStack.any.binByFactor = &lt;stack_bin_factor&gt;

runtime.Reconstruction.any.useSirt = &lt;use_sirt&gt;
comparam.sirtsetup.sirtsetup.LeaveIterations = &lt;sirt_iter&gt;

comparam.tilt.tilt.THICKNESS = &lt;recon_thickness&gt;

runtime.Postprocess.any.doTrimvol = &lt;run_trimvol&gt;
runtime.Trimvol.any.reorient = &lt;trimvol_reorient&gt;
        &#34;&#34;&#34;

        convert_dict = {
            &#39;use_rawtlt&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;use_rawtlt&#39;] else 0,
            &#39;pixel_size&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;pixel_size&#39;],
            &#39;rot_angle&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;rot_angle&#39;],
            &#39;gold_size&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;gold_size&#39;],
            &#39;adoc_template&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;setup&#39;][&#39;adoc_template&#39;],

            &#39;do_pos&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;positioning&#39;][&#39;do_positioning&#39;] else 0,
            &#39;pos_thickness&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;positioning&#39;][&#39;unbinned_thickness&#39;],

            &#39;corr_ctf&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;aligned_stack&#39;][&#39;correct_ctf&#39;] else 0,
            &#39;erase_gold&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;aligned_stack&#39;][&#39;erase_gold&#39;] else 0,
            &#39;filter_stack&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;aligned_stack&#39;][&#39;2d_filtering&#39;] else 0,
            &#39;stack_bin_factor&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;aligned_stack&#39;][&#39;bin_factor&#39;],

            &#39;recon_thickness&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;reconstruction&#39;][&#39;thickness&#39;],
            &#39;use_sirt&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;reconstruction&#39;][&#39;use_sirt&#39;] else 0,
            &#39;sirt_iter&#39;: self.params[&#39;BatchRunTomo&#39;][&#39;reconstruction&#39;][&#39;sirt_iter&#39;],

            &#39;run_trimvol&#39;: 1 if self.params[&#39;BatchRunTomo&#39;][&#39;postprocessing&#39;][&#39;run_trimvol&#39;] else 0,
            &#39;trimvol_reorient&#39;: {&#39;none&#39;: 0, &#39;flip&#39;: 1, &#39;rotate&#39;: 2}[
                self.params[&#39;BatchRunTomo&#39;][&#39;postprocessing&#39;][&#39;trimvol_reorient&#39;]]
        }

        for param in list(convert_dict.keys()):
            adoc_temp = adoc_temp.replace(f&#39;&lt;{param}&gt;&#39;, f&#39;{convert_dict[param]}&#39;)

        with open(&#39;./recon.adoc&#39;, &#39;w&#39;) as f:
            f.write(adoc_temp)

    def _get_brt_recon_command(self,
                               curr_ts: int,
                               ext=False,
                               ):
        &#34;&#34;&#34;
        Method to get command to run batchtomo for reconstruction

        Args:
            curr_ts: index of the tilt-series currently being processed

        Returns:
            list
        &#34;&#34;&#34;

        # Get indices of usable CPUs
        temp_cpu = [str(i) for i in range(1, mp.cpu_count() + 1)]

        cmd = [&#39;batchruntomo&#39;,
               &#39;-CPUMachineList&#39;, f&#34;{temp_cpu}&#34;,
               &#39;-GPUMachineList&#39;, &#39;1&#39;,
               &#39;-DirectiveFile&#39;, &#39;./recon.adoc&#39;,
               &#39;-RootName&#39;, f&#39;{self.rootname}_{curr_ts:04d}&#39;,
               &#39;-CurrentLocation&#39;, self._path_dict[curr_ts],
               &#39;-StartingStep&#39;, &#39;8&#39; if not ext else &#39;0&#39;,
               &#39;-EndingStep&#39;, &#39;20&#39; if not ext else &#39;0&#39;,
               ]

        return cmd

    def recon_stack(self, ext=False):
        &#34;&#34;&#34;
        Method to reconstruct specified stack(s) using IMOD batchtomo
        &#34;&#34;&#34;
        # Add log entry when job starts
        self.logObj(&#34;Ot2Rec-reconstruction (IMOD) started.&#34;)

        # Create adoc file
        self._get_adoc()

        error_count = 0
        tqdm_iter = tqdm(self._process_list, ncols=100)
        for curr_ts in tqdm_iter:
            tqdm_iter.set_description(f&#34;Reconstructing TS {curr_ts}...&#34;)

            # Get command for current tilt-series
            if ext:
                batchruntomo = subprocess.run(self._get_brt_recon_command(curr_ts, ext=True),
                                              stdout=subprocess.PIPE,
                                              stderr=subprocess.STDOUT,
                                              encoding=&#39;ascii&#39;,
                                              check=True
                )

            batchruntomo = subprocess.run(self._get_brt_recon_command(curr_ts, ext=False),
                                          stdout=subprocess.PIPE,
                                          stderr=subprocess.STDOUT,
                                          encoding=&#39;ascii&#39;,
                                          check=True
            )

            try:
                assert (not batchruntomo.stderr)
            except:
                error_count += 1
                self.logObj(level=&#34;warning&#34;,
                            message=f&#34;Batchtomo: An error has occurred ({batchruntomo.returncode}) on stack{curr_ts}.&#34;)
            else:
                self.stdout = batchruntomo.stdout
                self.update_recon_metadata()
                self.export_metadata()

        # Add log entry when job finishes
        if error_count == 0:
            self.logObj(&#34;All Ot2Rec-recon (IMOD) jobs successfully finished.&#34;)
        else:
            self.logObj(level=&#34;warning&#34;,
                        message=f&#34;All Ot2Rec-recon (IMOD) jobs finished. {error_count} of {len(tqdm_iter)} jobs failed.&#34;
            )


    def update_recon_metadata(self):
        &#34;&#34;&#34;
        Subroutine to update metadata after one set of runs
        &#34;&#34;&#34;

        # Search for files with output paths specified in the metadata
        # If the files don&#39;t exist, keep the line in the input metadata
        # If they do, move them to the output metadata

        _to_append = self._recon_images.loc[self._recon_images[&#39;recon_output&#39;].apply(lambda x: os.path.isfile(x))]
        self.meta_out = pd.concat([self.meta_out, _to_append],
                                  ignore_index=True)
        self._recon_images = self._recon_images.loc[~self._recon_images[&#39;recon_output&#39;].apply(
            lambda x: os.path.isfile(x))]

        # Sometimes data might be duplicated (unlikely) -- need to drop the duplicates
        self.meta_out.drop_duplicates(inplace=True)

    def export_metadata(self):
        &#34;&#34;&#34;
        Method to serialise output metadata, export as yaml
        &#34;&#34;&#34;

        yaml_file = self.proj_name + &#39;_recon_mdout.yaml&#39;
        meta_dict = self.meta_out.to_dict()
        meta_dict[&#39;recon_algor&#39;] = &#34;SIRT&#34; if self.params[&#34;BatchRunTomo&#34;][&#34;reconstruction&#34;][&#34;use_sirt&#34;] else &#34;WBP&#34;

        with open(yaml_file, &#39;w&#39;) as f:
            yaml.dump(self.meta_out.to_dict(), f, indent=4, sort_keys=False)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="Ot2Rec.recon.Recon.export_metadata"><code class="name flex">
<span>def <span class="ident">export_metadata</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method to serialise output metadata, export as yaml</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def export_metadata(self):
    &#34;&#34;&#34;
    Method to serialise output metadata, export as yaml
    &#34;&#34;&#34;

    yaml_file = self.proj_name + &#39;_recon_mdout.yaml&#39;
    meta_dict = self.meta_out.to_dict()
    meta_dict[&#39;recon_algor&#39;] = &#34;SIRT&#34; if self.params[&#34;BatchRunTomo&#34;][&#34;reconstruction&#34;][&#34;use_sirt&#34;] else &#34;WBP&#34;

    with open(yaml_file, &#39;w&#39;) as f:
        yaml.dump(self.meta_out.to_dict(), f, indent=4, sort_keys=False)</code></pre>
</details>
</dd>
<dt id="Ot2Rec.recon.Recon.recon_stack"><code class="name flex">
<span>def <span class="ident">recon_stack</span></span>(<span>self, ext=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Method to reconstruct specified stack(s) using IMOD batchtomo</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def recon_stack(self, ext=False):
    &#34;&#34;&#34;
    Method to reconstruct specified stack(s) using IMOD batchtomo
    &#34;&#34;&#34;
    # Add log entry when job starts
    self.logObj(&#34;Ot2Rec-reconstruction (IMOD) started.&#34;)

    # Create adoc file
    self._get_adoc()

    error_count = 0
    tqdm_iter = tqdm(self._process_list, ncols=100)
    for curr_ts in tqdm_iter:
        tqdm_iter.set_description(f&#34;Reconstructing TS {curr_ts}...&#34;)

        # Get command for current tilt-series
        if ext:
            batchruntomo = subprocess.run(self._get_brt_recon_command(curr_ts, ext=True),
                                          stdout=subprocess.PIPE,
                                          stderr=subprocess.STDOUT,
                                          encoding=&#39;ascii&#39;,
                                          check=True
            )

        batchruntomo = subprocess.run(self._get_brt_recon_command(curr_ts, ext=False),
                                      stdout=subprocess.PIPE,
                                      stderr=subprocess.STDOUT,
                                      encoding=&#39;ascii&#39;,
                                      check=True
        )

        try:
            assert (not batchruntomo.stderr)
        except:
            error_count += 1
            self.logObj(level=&#34;warning&#34;,
                        message=f&#34;Batchtomo: An error has occurred ({batchruntomo.returncode}) on stack{curr_ts}.&#34;)
        else:
            self.stdout = batchruntomo.stdout
            self.update_recon_metadata()
            self.export_metadata()

    # Add log entry when job finishes
    if error_count == 0:
        self.logObj(&#34;All Ot2Rec-recon (IMOD) jobs successfully finished.&#34;)
    else:
        self.logObj(level=&#34;warning&#34;,
                    message=f&#34;All Ot2Rec-recon (IMOD) jobs finished. {error_count} of {len(tqdm_iter)} jobs failed.&#34;
        )</code></pre>
</details>
</dd>
<dt id="Ot2Rec.recon.Recon.update_recon_metadata"><code class="name flex">
<span>def <span class="ident">update_recon_metadata</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Subroutine to update metadata after one set of runs</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_recon_metadata(self):
    &#34;&#34;&#34;
    Subroutine to update metadata after one set of runs
    &#34;&#34;&#34;

    # Search for files with output paths specified in the metadata
    # If the files don&#39;t exist, keep the line in the input metadata
    # If they do, move them to the output metadata

    _to_append = self._recon_images.loc[self._recon_images[&#39;recon_output&#39;].apply(lambda x: os.path.isfile(x))]
    self.meta_out = pd.concat([self.meta_out, _to_append],
                              ignore_index=True)
    self._recon_images = self._recon_images.loc[~self._recon_images[&#39;recon_output&#39;].apply(
        lambda x: os.path.isfile(x))]

    # Sometimes data might be duplicated (unlikely) -- need to drop the duplicates
    self.meta_out.drop_duplicates(inplace=True)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="Ot2Rec" href="index.html">Ot2Rec</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="Ot2Rec.recon.create_yaml" href="#Ot2Rec.recon.create_yaml">create_yaml</a></code></li>
<li><code><a title="Ot2Rec.recon.run" href="#Ot2Rec.recon.run">run</a></code></li>
<li><code><a title="Ot2Rec.recon.update_yaml" href="#Ot2Rec.recon.update_yaml">update_yaml</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="Ot2Rec.recon.Recon" href="#Ot2Rec.recon.Recon">Recon</a></code></h4>
<ul class="">
<li><code><a title="Ot2Rec.recon.Recon.export_metadata" href="#Ot2Rec.recon.Recon.export_metadata">export_metadata</a></code></li>
<li><code><a title="Ot2Rec.recon.Recon.recon_stack" href="#Ot2Rec.recon.Recon.recon_stack">recon_stack</a></code></li>
<li><code><a title="Ot2Rec.recon.Recon.update_recon_metadata" href="#Ot2Rec.recon.Recon.update_recon_metadata">update_recon_metadata</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>